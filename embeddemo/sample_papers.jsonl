{"search_keyword": "few-shot learning sample complexity", "id": "2502.17872v1", "title": "Contrastive Learning with Nasty Noise", "abstract": "Contrastive learning has emerged as a powerful paradigm for self-supervised representation learning. This work analyzes the theoretical limits of contrastive learning under nasty noise, where an adversary modifies or replaces training samples. Using PAC learning and VC-dimension analysis, lower and upper bounds on sample complexity in adversarial settings are established. Additionally, data-dependent sample complexity bounds based on the l2-distance function are derived.", "url": "http://arxiv.org/abs/2502.17872v1", "year": 2025, "categories": ["cs.LG", "cs.AI"]}
{"search_keyword": "few-shot learning sample complexity", "id": "2112.15578v1", "title": "Importance of Empirical Sample Complexity Analysis for Offline Reinforcement Learning", "abstract": "We hypothesize that empirically studying the sample complexity of offline reinforcement learning (RL) is crucial for the practical applications of RL in the real world. Several recent works have demonstrated the ability to learn policies directly from offline data. In this work, we ask the question of the dependency on the number of samples for learning from offline data. Our objective is to emphasize that studying sample complexity for offline RL is important, and is an indicator of the usefulness of existing offline algorithms. We propose an evaluation approach for sample complexity analysis of offline RL.", "url": "http://arxiv.org/abs/2112.15578v1", "year": 2021, "categories": ["cs.LG", "cs.AI"]}
{"search_keyword": "few-shot learning sample complexity", "id": "2210.12529v3", "title": "On-Demand Sampling: Learning Optimally from Multiple Distributions", "abstract": "Social and real-world considerations such as robustness, fairness, social welfare and multi-agent tradeoffs have given rise to multi-distribution learning paradigms, such as collaborative learning, group distributionally robust optimization, and fair federated learning. In each of these settings, a learner seeks to uniformly minimize its expected loss over $n$ predefined data distributions, while using as few samples as possible. In this paper, we establish the optimal sample complexity of these learning paradigms and give algorithms that meet this sample complexity. Importantly, our sample complexity bounds for multi-distribution learning exceed that of learning a single distribution by only an additive factor of $n \\log(n) / \\epsilon^2$. This improves upon the best known sample complexity bounds for fair federated learning by Mohri et al. and collaborative learning by Nguyen and Zakynthinou by multiplicative factors of $n$ and $\\log(n)/\\epsilon^3$, respectively. We also provide the first sample complexity bounds for the group DRO objective of Sagawa et al. To guarantee these optimal sample complexity bounds, our algorithms learn to sample from data distributions on demand. Our algorithm design and analysis are enabled by our extensions of online learning techniques for solving stochastic zero-sum games. In particular, we contribute stochastic variants of no-regret dynamics that can trade off between players' differing sampling costs.", "url": "http://arxiv.org/abs/2210.12529v3", "year": 2022, "categories": ["cs.LG", "cs.CY"]}
{"search_keyword": "few-shot learning sample complexity", "id": "2303.04268v1", "title": "On the Sample Complexity of Vanilla Model-Based Offline Reinforcement Learning with Dependent Samples", "abstract": "Offline reinforcement learning (offline RL) considers problems where learning is performed using only previously collected samples and is helpful for the settings in which collecting new data is costly or risky. In model-based offline RL, the learner performs estimation (or optimization) using a model constructed according to the empirical transition frequencies. We analyze the sample complexity of vanilla model-based offline RL with dependent samples in the infinite-horizon discounted-reward setting. In our setting, the samples obey the dynamics of the Markov decision process and, consequently, may have interdependencies. Under no assumption of independent samples, we provide a high-probability, polynomial sample complexity bound for vanilla model-based off-policy evaluation that requires partial or uniform coverage. We extend this result to the off-policy optimization under uniform coverage. As a comparison to the model-based approach, we analyze the sample complexity of off-policy evaluation with vanilla importance sampling in the infinite-horizon setting. Finally, we provide an estimator that outperforms the sample-mean estimator for almost deterministic dynamics that are prevalent in reinforcement learning.", "url": "http://arxiv.org/abs/2303.04268v1", "year": 2023, "categories": ["cs.LG", "cs.AI"]}
{"search_keyword": "few-shot learning sample complexity", "id": "1704.02598v2", "title": "A Sample Complexity Measure with Applications to Learning Optimal Auctions", "abstract": "We introduce a new sample complexity measure, which we refer to as split-sample growth rate. For any hypothesis $H$ and for any sample $S$ of size $m$, the split-sample growth rate $\\hat{\\tau}_H(m)$ counts how many different hypotheses can empirical risk minimization output on any sub-sample of $S$ of size $m/2$. We show that the expected generalization error is upper bounded by $O\\left(\\sqrt{\\frac{\\log(\\hat{\\tau}_H(2m))}{m}}\\right)$. Our result is enabled by a strengthening of the Rademacher complexity analysis of the expected generalization error. We show that this sample complexity measure, greatly simplifies the analysis of the sample complexity of optimal auction design, for many auction classes studied in the literature. Their sample complexity can be derived solely by noticing that in these auction classes, ERM on any sample or sub-sample will pick parameters that are equal to one of the points in the sample.", "url": "http://arxiv.org/abs/1704.02598v2", "year": 2017, "categories": ["cs.GT", "cs.LG", "math.ST", "stat.TH"]}
{"search_keyword": "few-shot learning sample complexity", "id": "2103.15690v1", "title": "The Sample Complexity of Distribution-Free Parity Learning in the Robust Shuffle Model", "abstract": "We provide a lowerbound on the sample complexity of distribution-free parity learning in the realizable case in the shuffle model of differential privacy. Namely, we show that the sample complexity of learning $d$-bit parity functions is $\\Omega(2^{d/2})$. Our result extends a recent similar lowerbound on the sample complexity of private agnostic learning of parity functions in the shuffle model by Cheu and Ullman. We also sketch a simple shuffle model protocol demonstrating that our results are tight up to $poly(d)$ factors.", "url": "http://arxiv.org/abs/2103.15690v1", "year": 2021, "categories": ["cs.LG", "cs.CR"]}
{"search_keyword": "few-shot learning sample complexity", "id": "2006.06352v2", "title": "PAC Bounds for Imitation and Model-based Batch Learning of Contextual Markov Decision Processes", "abstract": "We consider the problem of batch multi-task reinforcement learning with observed context descriptors, motivated by its application to personalized medical treatment. In particular, we study two general classes of learning algorithms: direct policy learning (DPL), an imitation-learning based approach which learns from expert trajectories, and model-based learning. First, we derive sample complexity bounds for DPL, and then show that model-based learning from expert actions can, even with a finite model class, be impossible. After relaxing the conditions under which the model-based approach is expected to learn by allowing for greater coverage of state-action space, we provide sample complexity bounds for model-based learning with finite model classes, showing that there exist model classes with sample complexity exponential in their statistical complexity. We then derive a sample complexity upper bound for model-based learning based on a measure of concentration of the data distribution. Our results give formal justification for imitation learning over model-based learning in this setting.", "url": "http://arxiv.org/abs/2006.06352v2", "year": 2020, "categories": ["cs.LG", "stat.ML"]}
{"search_keyword": "few-shot learning sample complexity", "id": "2312.00379v1", "title": "Optimal Sample Complexity of Contrastive Learning", "abstract": "Contrastive learning is a highly successful technique for learning representations of data from labeled tuples, specifying the distance relations within the tuple. We study the sample complexity of contrastive learning, i.e. the minimum number of labeled tuples sufficient for getting high generalization accuracy. We give tight bounds on the sample complexity in a variety of settings, focusing on arbitrary distance functions, both general $\\ell_p$-distances, and tree metrics. Our main result is an (almost) optimal bound on the sample complexity of learning $\\ell_p$-distances for integer $p$. For any $p \\ge 1$ we show that $\\tilde \\Theta(\\min(nd,n^2))$ labeled tuples are necessary and sufficient for learning $d$-dimensional representations of $n$-point datasets. Our results hold for an arbitrary distribution of the input samples and are based on giving the corresponding bounds on the Vapnik-Chervonenkis/Natarajan dimension of the associated problems. We further show that the theoretical bounds on sample complexity obtained via VC/Natarajan dimension can have strong predictive power for experimental results, in contrast with the folklore belief about a substantial gap between the statistical learning theory and the practice of deep learning.", "url": "http://arxiv.org/abs/2312.00379v1", "year": 2023, "categories": ["cs.LG", "stat.ML"]}
{"search_keyword": "few-shot learning sample complexity", "id": "1402.6278v4", "title": "Sample Complexity Bounds on Differentially Private Learning via Communication Complexity", "abstract": "In this work we analyze the sample complexity of classification by differentially private algorithms. Differential privacy is a strong and well-studied notion of privacy introduced by Dwork et al. (2006) that ensures that the output of an algorithm leaks little information about the data point provided by any of the participating individuals. Sample complexity of private PAC and agnostic learning was studied in a number of prior works starting with (Kasiviswanathan et al., 2008) but a number of basic questions still remain open, most notably whether learning with privacy requires more samples than learning without privacy. We show that the sample complexity of learning with (pure) differential privacy can be arbitrarily higher than the sample complexity of learning without the privacy constraint or the sample complexity of learning with approximate differential privacy. Our second contribution and the main tool is an equivalence between the sample complexity of (pure) differentially private learning of a concept class $C$ (or $SCDP(C)$) and the randomized one-way communication complexity of the evaluation problem for concepts from $C$. Using this equivalence we prove the following bounds: 1. $SCDP(C) = \\Omega(LDim(C))$, where $LDim(C)$ is the Littlestone's (1987) dimension characterizing the number of mistakes in the online-mistake-bound learning model. Known bounds on $LDim(C)$ then imply that $SCDP(C)$ can be much higher than the VC-dimension of $C$. 2. For any $t$, there exists a class $C$ such that $LDim(C)=2$ but $SCDP(C) \\geq t$. 3. For any $t$, there exists a class $C$ such that the sample complexity of (pure) $\\alpha$-differentially private PAC learning is $\\Omega(t/\\alpha)$ but the sample complexity of the relaxed $(\\alpha,\\beta)$-differentially private PAC learning is $O(\\log(1/\\beta)/\\alpha)$. This resolves an open problem of Beimel et al. (2013b).", "url": "http://arxiv.org/abs/1402.6278v4", "year": 2014, "categories": ["cs.DS", "cs.CC", "cs.LG"]}
{"search_keyword": "few-shot learning sample complexity", "id": "1302.3579v1", "title": "On the Sample Complexity of Learning Bayesian Networks", "abstract": "In recent years there has been an increasing interest in learning Bayesian networks from data. One of the most effective methods for learning such networks is based on the minimum description length (MDL) principle. Previous work has shown that this learning procedure is asymptotically successful: with probability one, it will converge to the target distribution, given a sufficient number of samples. However, the rate of this convergence has been hitherto unknown. In this work we examine the sample complexity of MDL based learning procedures for Bayesian networks. We show that the number of samples needed to learn an epsilon-close approximation (in terms of entropy distance) with confidence delta is O((1/epsilon)^(4/3)log(1/epsilon)log(1/delta)loglog (1/delta)). This means that the sample complexity is a low-order polynomial in the error threshold and sub-linear in the confidence bound. We also discuss how the constants in this term depend on the complexity of the target distribution. Finally, we address questions of asymptotic minimality and propose a method for using the sample complexity results to speed up the learning process.", "url": "http://arxiv.org/abs/1302.3579v1", "year": 2013, "categories": ["cs.LG", "stat.ML"]}
{"search_keyword": "meta-learning theoretical bounds", "id": "2109.14595v2", "title": "Generalization Bounds For Meta-Learning: An Information-Theoretic Analysis", "abstract": "We derive a novel information-theoretic analysis of the generalization property of meta-learning algorithms. Concretely, our analysis proposes a generic understanding of both the conventional learning-to-learn framework and the modern model-agnostic meta-learning (MAML) algorithms. Moreover, we provide a data-dependent generalization bound for a stochastic variant of MAML, which is non-vacuous for deep few-shot learning. As compared to previous bounds that depend on the square norm of gradients, empirical validations on both simulated data and a well-known few-shot benchmark show that our bound is orders of magnitude tighter in most situations.", "url": "http://arxiv.org/abs/2109.14595v2", "year": 2021, "categories": ["cs.LG", "stat.ML"]}
{"search_keyword": "meta-learning theoretical bounds", "id": "2011.02872v2", "title": "Transfer Meta-Learning: Information-Theoretic Bounds and Information Meta-Risk Minimization", "abstract": "Meta-learning automatically infers an inductive bias by observing data from a number of related tasks. The inductive bias is encoded by hyperparameters that determine aspects of the model class or training algorithm, such as initialization or learning rate. Meta-learning assumes that the learning tasks belong to a task environment, and that tasks are drawn from the same task environment both during meta-training and meta-testing. This, however, may not hold true in practice. In this paper, we introduce the problem of transfer meta-learning, in which tasks are drawn from a target task environment during meta-testing that may differ from the source task environment observed during meta-training. Novel information-theoretic upper bounds are obtained on the transfer meta-generalization gap, which measures the difference between the meta-training loss, available at the meta-learner, and the average loss on meta-test data from a new, randomly selected, task in the target task environment. The first bound, on the average transfer meta-generalization gap, captures the meta-environment shift between source and target task environments via the KL divergence between source and target data distributions. The second, PAC-Bayesian bound, and the third, single-draw bound, account for this shift via the log-likelihood ratio between source and target task distributions. Furthermore, two transfer meta-learning solutions are introduced. For the first, termed Empirical Meta-Risk Minimization (EMRM), we derive bounds on the average optimality gap. The second, referred to as Information Meta-Risk Minimization (IMRM), is obtained by minimizing the PAC-Bayesian bound. IMRM is shown via experiments to potentially outperform EMRM.", "url": "http://arxiv.org/abs/2011.02872v2", "year": 2020, "categories": ["cs.LG", "cs.IT", "eess.SP", "math.IT"]}
{"search_keyword": "meta-learning theoretical bounds", "id": "2311.02879v3", "title": "Exploring Active Learning in Meta-Learning: Enhancing Context Set Labeling", "abstract": "Most meta-learning methods assume that the (very small) context set used to establish a new task at test time is passively provided. In some settings, however, it is feasible to actively select which points to label; the potential gain from a careful choice is substantial, but the setting requires major differences from typical active learning setups. We clarify the ways in which active meta-learning can be used to label a context set, depending on which parts of the meta-learning process use active learning. Within this framework, we propose a natural algorithm based on fitting Gaussian mixtures for selecting which points to label; though simple, the algorithm also has theoretical motivation. The proposed algorithm outperforms state-of-the-art active learning methods when used with various meta-learning algorithms across several benchmark datasets.", "url": "http://arxiv.org/abs/2311.02879v3", "year": 2023, "categories": ["cs.LG"]}
{"search_keyword": "meta-learning theoretical bounds", "id": "2106.09017v1", "title": "Bridging Multi-Task Learning and Meta-Learning: Towards Efficient Training and Effective Adaptation", "abstract": "Multi-task learning (MTL) aims to improve the generalization of several related tasks by learning them jointly. As a comparison, in addition to the joint training scheme, modern meta-learning allows unseen tasks with limited labels during the test phase, in the hope of fast adaptation over them. Despite the subtle difference between MTL and meta-learning in the problem formulation, both learning paradigms share the same insight that the shared structure between existing training tasks could lead to better generalization and adaptation. In this paper, we take one important step further to understand the close connection between these two learning paradigms, through both theoretical analysis and empirical investigation. Theoretically, we first demonstrate that MTL shares the same optimization formulation with a class of gradient-based meta-learning (GBML) algorithms. We then prove that for over-parameterized neural networks with sufficient depth, the learned predictive functions of MTL and GBML are close. In particular, this result implies that the predictions given by these two models are similar over the same unseen task. Empirically, we corroborate our theoretical findings by showing that, with proper implementation, MTL is competitive against state-of-the-art GBML algorithms on a set of few-shot image classification benchmarks. Since existing GBML algorithms often involve costly second-order bi-level optimization, our first-order MTL method is an order of magnitude faster on large-scale datasets such as mini-ImageNet. We believe this work could help bridge the gap between these two learning paradigms, and provide a computationally efficient alternative to GBML that also supports fast task adaptation.", "url": "http://arxiv.org/abs/2106.09017v1", "year": 2021, "categories": ["cs.LG", "cs.CV", "stat.ML"]}
{"search_keyword": "meta-learning theoretical bounds", "id": "1810.03548v1", "title": "Meta-Learning: A Survey", "abstract": "Meta-learning, or learning to learn, is the science of systematically observing how different machine learning approaches perform on a wide range of learning tasks, and then learning from this experience, or meta-data, to learn new tasks much faster than otherwise possible. Not only does this dramatically speed up and improve the design of machine learning pipelines or neural architectures, it also allows us to replace hand-engineered algorithms with novel approaches learned in a data-driven way. In this chapter, we provide an overview of the state of the art in this fascinating and continuously evolving field.", "url": "http://arxiv.org/abs/1810.03548v1", "year": 2018, "categories": ["cs.LG", "stat.ML"]}
{"search_keyword": "meta-learning theoretical bounds", "id": "2504.08940v1", "title": "Combining Forecasts using Meta-Learning: A Comparative Study for Complex Seasonality", "abstract": "In this paper, we investigate meta-learning for combining forecasts generated by models of different types. While typical approaches for combining forecasts involve simple averaging, machine learning techniques enable more sophisticated methods of combining through meta-learning, leading to improved forecasting accuracy. We use linear regression, $k$-nearest neighbors, multilayer perceptron, random forest, and long short-term memory as meta-learners. We define global and local meta-learning variants for time series with complex seasonality and compare meta-learners on multiple forecasting problems, demonstrating their superior performance compared to simple averaging.", "url": "http://arxiv.org/abs/2504.08940v1", "year": 2025, "categories": ["cs.LG", "cs.AI"]}
{"search_keyword": "meta-learning theoretical bounds", "id": "1806.06207v1", "title": "Meta-learning: searching in the model space", "abstract": "There is no free lunch, no single learning algorithm that will outperform other algorithms on all data. In practice different approaches are tried and the best algorithm selected. An alternative solution is to build new algorithms on demand by creating a framework that accommodates many algorithms. The best combination of parameters and procedures is searched here in the space of all possible models belonging to the framework of Similarity-Based Methods (SBMs). Such meta-learning approach gives a chance to find the best method in all cases. Issues related to the meta-learning and first tests of this approach are presented.", "url": "http://arxiv.org/abs/1806.06207v1", "year": 2018, "categories": ["cs.LG", "cs.AI", "stat.ML"]}
{"search_keyword": "meta-learning theoretical bounds", "id": "1911.04336v1", "title": "Fair Meta-Learning: Learning How to Learn Fairly", "abstract": "Data sets for fairness relevant tasks can lack examples or be biased according to a specific label in a sensitive attribute. We demonstrate the usefulness of weight based meta-learning approaches in such situations. For models that can be trained through gradient descent, we demonstrate that there are some parameter configurations that allow models to be optimized from a few number of gradient steps and with minimal data which are both fair and accurate. To learn such weight sets, we adapt the popular MAML algorithm to Fair-MAML by the inclusion of a fairness regularization term. In practice, Fair-MAML allows practitioners to train fair machine learning models from only a few examples when data from related tasks is available. We empirically exhibit the value of this technique by comparing to relevant baselines.", "url": "http://arxiv.org/abs/1911.04336v1", "year": 2019, "categories": ["cs.LG", "stat.ML"]}
{"search_keyword": "meta-learning theoretical bounds", "id": "1911.11170v3", "title": "Real-Time Object Tracking via Meta-Learning: Efficient Model Adaptation and One-Shot Channel Pruning", "abstract": "We propose a novel meta-learning framework for real-time object tracking with efficient model adaptation and channel pruning. Given an object tracker, our framework learns to fine-tune its model parameters in only a few iterations of gradient-descent during tracking while pruning its network channels using the target ground-truth at the first frame. Such a learning problem is formulated as a meta-learning task, where a meta-tracker is trained by updating its meta-parameters for initial weights, learning rates, and pruning masks through carefully designed tracking simulations. The integrated meta-tracker greatly improves tracking performance by accelerating the convergence of online learning and reducing the cost of feature computation. Experimental evaluation on the standard datasets demonstrates its outstanding accuracy and speed compared to the state-of-the-art methods.", "url": "http://arxiv.org/abs/1911.11170v3", "year": 2019, "categories": ["cs.CV"]}
{"search_keyword": "meta-learning theoretical bounds", "id": "2002.06753v3", "title": "Unraveling Meta-Learning: Understanding Feature Representations for Few-Shot Tasks", "abstract": "Meta-learning algorithms produce feature extractors which achieve state-of-the-art performance on few-shot classification. While the literature is rich with meta-learning methods, little is known about why the resulting feature extractors perform so well. We develop a better understanding of the underlying mechanics of meta-learning and the difference between models trained using meta-learning and models which are trained classically. In doing so, we introduce and verify several hypotheses for why meta-learned models perform better. Furthermore, we develop a regularizer which boosts the performance of standard training routines for few-shot classification. In many cases, our routine outperforms meta-learning while simultaneously running an order of magnitude faster.", "url": "http://arxiv.org/abs/2002.06753v3", "year": 2020, "categories": ["cs.LG", "cs.CV", "stat.ML"]}
{"search_keyword": "task similarity generalization", "id": "2006.07212v2", "title": "Task-similarity Aware Meta-learning through Nonparametric Kernel Regression", "abstract": "This paper investigates the use of nonparametric kernel-regression to obtain a tasksimilarity aware meta-learning algorithm. Our hypothesis is that the use of tasksimilarity helps meta-learning when the available tasks are limited and may contain outlier/ dissimilar tasks. While existing meta-learning approaches implicitly assume the tasks as being similar, it is generally unclear how this task-similarity could be quantified and used in the learning. As a result, most popular metalearning approaches do not actively use the similarity/dissimilarity between the tasks, but rely on availability of huge number of tasks for their working. Our contribution is a novel framework for meta-learning that explicitly uses task-similarity in the form of kernels and an associated meta-learning algorithm. We model the task-specific parameters to belong to a reproducing kernel Hilbert space where the kernel function captures the similarity across tasks. The proposed algorithm iteratively learns a meta-parameter which is used to assign a task-specific descriptor for every task. The task descriptors are then used to quantify the task-similarity through the kernel function. We show how our approach conceptually generalizes the popular meta-learning approaches of model-agnostic meta-learning (MAML) and Meta-stochastic gradient descent (Meta-SGD) approaches. Numerical experiments with regression tasks show that our algorithm outperforms these approaches when the number of tasks is limited, even in the presence of outlier or dissimilar tasks. This supports our hypothesis that task-similarity helps improve the metalearning performance in task-limited and adverse settings.", "url": "http://arxiv.org/abs/2006.07212v2", "year": 2020, "categories": ["cs.LG", "stat.ML"]}
{"search_keyword": "task similarity generalization", "id": "2007.00350v3", "title": "Adaptive Procedural Task Generation for Hard-Exploration Problems", "abstract": "We introduce Adaptive Procedural Task Generation (APT-Gen), an approach to progressively generate a sequence of tasks as curricula to facilitate reinforcement learning in hard-exploration problems. At the heart of our approach, a task generator learns to create tasks from a parameterized task space via a black-box procedural generation module. To enable curriculum learning in the absence of a direct indicator of learning progress, we propose to train the task generator by balancing the agent's performance in the generated tasks and the similarity to the target tasks. Through adversarial training, the task similarity is adaptively estimated by a task discriminator defined on the agent's experiences, allowing the generated tasks to approximate target tasks of unknown parameterization or outside of the predefined task space. Our experiments on the grid world and robotic manipulation task domains show that APT-Gen achieves substantially better performance than various existing baselines by generating suitable tasks of rich variations.", "url": "http://arxiv.org/abs/2007.00350v3", "year": 2020, "categories": ["cs.LG", "cs.RO", "stat.ML"]}
{"search_keyword": "task similarity generalization", "id": "2506.02164v1", "title": "Quantifying task-relevant representational similarity using decision variable correlation", "abstract": "Previous studies have compared the brain and deep neural networks trained on image classification. Intriguingly, while some suggest that their representations are highly similar, others argued the opposite. Here, we propose a new approach to characterize the similarity of the decision strategies of two observers (models or brains) using decision variable correlation (DVC). DVC quantifies the correlation between decoded decisions on individual samples in a classification task and thus can capture task-relevant information rather than general representational alignment. We evaluate this method using monkey V4/IT recordings and models trained on image classification tasks. We find that model--model similarity is comparable to monkey--monkey similarity, whereas model--monkey similarity is consistently lower and, surprisingly, decreases with increasing ImageNet-1k performance. While adversarial training enhances robustness, it does not improve model--monkey similarity in task-relevant dimensions; however, it markedly increases model--model similarity. Similarly, pre-training on larger datasets does not improve model--monkey similarity. These results suggest a fundamental divergence between the task-relevant representations in monkey V4/IT and those learned by models trained on image classification tasks.", "url": "http://arxiv.org/abs/2506.02164v1", "year": 2025, "categories": ["cs.CV", "cs.LG", "q-bio.NC", "q-bio.QM"]}
{"search_keyword": "task similarity generalization", "id": "2407.06488v2", "title": "Towards Understanding Multi-Task Learning (Generalization) of LLMs via Detecting and Exploring Task-Specific Neurons", "abstract": "While large language models (LLMs) have demonstrated superior multi-task capabilities, understanding the learning mechanisms behind this is still a challenging problem. In this paper, we attempt to understand such mechanisms from the perspective of neurons. Specifically, we detect task-sensitive neurons in LLMs via gradient attribution on task-specific data. Through extensive deactivation and fine-tuning experiments, we demonstrate that the detected neurons are highly correlated with the given task, which we term as task-specific neurons. With these identified task-specific neurons, we delve into two common problems in multi-task learning and continuous learning: Generalization and Catastrophic Forgetting. We find that the overlap of task-specific neurons is strongly associated with generalization and specialization across tasks. Interestingly, at certain layers of LLMs, there is a high similarity in the parameters of different task-specific neurons, and such similarity is highly correlated with the generalization performance. Inspired by these findings, we propose a neuron-level continuous fine-tuning method that only fine-tunes the current task-specific neurons during continuous learning, and extensive experiments demonstrate the effectiveness of the proposed method. Our study provides insights into the interpretability of LLMs in multi-task learning.", "url": "http://arxiv.org/abs/2407.06488v2", "year": 2024, "categories": ["cs.CL", "cs.LG"]}
{"search_keyword": "task similarity generalization", "id": "2503.12923v1", "title": "Lifelong Reinforcement Learning with Similarity-Driven Weighting by Large Models", "abstract": "Lifelong Reinforcement Learning (LRL) holds significant potential for addressing sequential tasks, but it still faces considerable challenges. A key difficulty lies in effectively preventing catastrophic forgetting and facilitating knowledge transfer while maintaining reliable decision-making performance across subsequent tasks in dynamic environments. To tackle this, we propose a novel framework, SDW (Similarity-Driven Weighting Framework), which leverages large-language-model-generated dynamic functions to precisely control the training process. The core of SDW lies in two functions pre-generated by large models: the task similarity function and the weight computation function. The task similarity function extracts multidimensional features from task descriptions to quantify the similarities and differences between tasks in terms of states, actions, and rewards. The weight computation function dynamically generates critical training parameters based on the similarity information, including the proportion of old task data stored in the Replay Buffer and the strategy consistency weight in the loss function, enabling an adaptive balance between learning new tasks and transferring knowledge from previous tasks. By generating function code offline prior to training, rather than relying on large-model inference during the training process, the SDW framework reduces computational overhead while maintaining efficiency in sequential task scenarios. Experimental results on Atari and MiniHack sequential tasks demonstrate that SDW significantly outperforms existing lifelong reinforcement learning methods.", "url": "http://arxiv.org/abs/2503.12923v1", "year": 2025, "categories": ["cs.LG", "cs.SI"]}
{"search_keyword": "task similarity generalization", "id": "2208.09427v1", "title": "Curbing Task Interference using Representation Similarity-Guided Multi-Task Feature Sharing", "abstract": "Multi-task learning of dense prediction tasks, by sharing both the encoder and decoder, as opposed to sharing only the encoder, provides an attractive front to increase both accuracy and computational efficiency. When the tasks are similar, sharing the decoder serves as an additional inductive bias providing more room for tasks to share complementary information among themselves. However, increased sharing exposes more parameters to task interference which likely hinders both generalization and robustness. Effective ways to curb this interference while exploiting the inductive bias of sharing the decoder remains an open challenge. To address this challenge, we propose Progressive Decoder Fusion (PDF) to progressively combine task decoders based on inter-task representation similarity. We show that this procedure leads to a multi-task network with better generalization to in-distribution and out-of-distribution data and improved robustness to adversarial attacks. Additionally, we observe that the predictions of different tasks of this multi-task network are more consistent with each other.", "url": "http://arxiv.org/abs/2208.09427v1", "year": 2022, "categories": ["cs.CV", "cs.AI"]}
{"search_keyword": "task similarity generalization", "id": "2305.00441v1", "title": "Multi-Task Structural Learning using Local Task Similarity induced Neuron Creation and Removal", "abstract": "Multi-task learning has the potential to improve generalization by maximizing positive transfer between tasks while reducing task interference. Fully achieving this potential is hindered by manually designed architectures that remain static throughout training. On the contrary, learning in the brain occurs through structural changes that are in tandem with changes in synaptic strength. Thus, we propose \\textit{Multi-Task Structural Learning (MTSL)} that simultaneously learns the multi-task architecture and its parameters. MTSL begins with an identical single-task network for each task and alternates between a task-learning phase and a structural-learning phase. In the task learning phase, each network specializes in the corresponding task. In each of the structural learning phases, starting from the earliest layer, locally similar task layers first transfer their knowledge to a newly created group layer before being removed. MTSL then uses the group layer in place of the corresponding removed task layers and moves on to the next layers. Our empirical results show that MTSL achieves competitive generalization with various baselines and improves robustness to out-of-distribution data.", "url": "http://arxiv.org/abs/2305.00441v1", "year": 2023, "categories": ["cs.LG", "cs.AI", "cs.CV", "cs.NE"]}
{"search_keyword": "task similarity generalization", "id": "2303.05092v4", "title": "Task Aware Dreamer for Task Generalization in Reinforcement Learning", "abstract": "A long-standing goal of reinforcement learning is to acquire agents that can learn on training tasks and generalize well on unseen tasks that may share a similar dynamic but with different reward functions. The ability to generalize across tasks is important as it determines an agent's adaptability to real-world scenarios where reward mechanisms might vary. In this work, we first show that training a general world model can utilize similar structures in these tasks and help train more generalizable agents. Extending world models into the task generalization setting, we introduce a novel method named Task Aware Dreamer (TAD), which integrates reward-informed features to identify consistent latent characteristics across tasks. Within TAD, we compute the variational lower bound of sample data log-likelihood, which introduces a new term designed to differentiate tasks using their states, as the optimization objective of our reward-informed world models. To demonstrate the advantages of the reward-informed policy in TAD, we introduce a new metric called Task Distribution Relevance (TDR) which quantitatively measures the relevance of different tasks. For tasks exhibiting a high TDR, i.e., the tasks differ significantly, we illustrate that Markovian policies struggle to distinguish them, thus it is necessary to utilize reward-informed policies in TAD. Extensive experiments in both image-based and state-based tasks show that TAD can significantly improve the performance of handling different tasks simultaneously, especially for those with high TDR, and display a strong generalization ability to unseen tasks.", "url": "http://arxiv.org/abs/2303.05092v4", "year": 2023, "categories": ["cs.LG"]}
{"search_keyword": "task similarity generalization", "id": "1508.03329v1", "title": "Multi-Task Learning with Group-Specific Feature Space Sharing", "abstract": "When faced with learning a set of inter-related tasks from a limited amount of usable data, learning each task independently may lead to poor generalization performance. Multi-Task Learning (MTL) exploits the latent relations between tasks and overcomes data scarcity limitations by co-learning all these tasks simultaneously to offer improved performance. We propose a novel Multi-Task Multiple Kernel Learning framework based on Support Vector Machines for binary classification tasks. By considering pair-wise task affinity in terms of similarity between a pair's respective feature spaces, the new framework, compared to other similar MTL approaches, offers a high degree of flexibility in determining how similar feature spaces should be, as well as which pairs of tasks should share a common feature space in order to benefit overall performance. The associated optimization problem is solved via a block coordinate descent, which employs a consensus-form Alternating Direction Method of Multipliers algorithm to optimize the Multiple Kernel Learning weights and, hence, to determine task affinities. Empirical evaluation on seven data sets exhibits a statistically significant improvement of our framework's results compared to the ones of several other Clustered Multi-Task Learning methods.", "url": "http://arxiv.org/abs/1508.03329v1", "year": 2015, "categories": ["cs.LG"]}
{"search_keyword": "task similarity generalization", "id": "2002.04813v1", "title": "Deep Multi-Task Augmented Feature Learning via Hierarchical Graph Neural Network", "abstract": "Deep multi-task learning attracts much attention in recent years as it achieves good performance in many applications. Feature learning is important to deep multi-task learning for sharing common information among tasks. In this paper, we propose a Hierarchical Graph Neural Network (HGNN) to learn augmented features for deep multi-task learning. The HGNN consists of two-level graph neural networks. In the low level, an intra-task graph neural network is responsible of learning a powerful representation for each data point in a task by aggregating its neighbors. Based on the learned representation, a task embedding can be generated for each task in a similar way to max pooling. In the second level, an inter-task graph neural network updates task embeddings of all the tasks based on the attention mechanism to model task relations. Then the task embedding of one task is used to augment the feature representation of data points in this task. Moreover, for classification tasks, an inter-class graph neural network is introduced to conduct similar operations on a finer granularity, i.e., the class level, to generate class embeddings for each class in all the tasks use class embeddings to augment the feature representation. The proposed feature augmentation strategy can be used in many deep multi-task learning models. we analyze the HGNN in terms of training and generalization losses. Experiments on real-world datastes show the significant performance improvement when using this strategy.", "url": "http://arxiv.org/abs/2002.04813v1", "year": 2020, "categories": ["cs.LG", "stat.ML"]}
{"search_keyword": "model capacity generalization", "id": "0711.2489v1", "title": "Axiomatic structure of k-additive capacities", "abstract": "In this paper we deal with the problem of axiomatizing the preference relations modelled through Choquet integral with respect to a $k$-additive capacity, i.e. whose M\\\"obius transform vanishes for subsets of more than $k$ elements. Thus, $k$-additive capacities range from probability measures ($k=1$) to general capacities ($k=n$). The axiomatization is done in several steps, starting from symmetric 2-additive capacities, a case related to the Gini index, and finishing with general $k$-additive capacities. We put an emphasis on 2-additive capacities. Our axiomatization is done in the framework of social welfare, and complete previous results of Weymark, Gilboa and Ben Porath, and Gajdos.", "url": "http://arxiv.org/abs/0711.2489v1", "year": 2007, "categories": ["cs.DM"]}
{"search_keyword": "model capacity generalization", "id": "2408.05653v1", "title": "Measuring and Controlling Fishing Capacity for Chinese Inshore Fleets", "abstract": "The fishing capacity and capacity utilization for Chinese inshore fleets over the latest 13 years were measured using the DEA method. Relevant models were then established to analyze the relationships between capacity output, capacity utilization, and income, and the function of collecting taxes to control fishing capacity was quantitatively simulated. It was pointed out that the tax system would be effective for curtailing fishing capacity and improving the efficiency of the entire fishing industry in China, provided that the tax rate is not too low. Finally, it was suggested that collecting taxes at a proper rate be implemented for Chinese inshore fishing fleets.", "url": "http://arxiv.org/abs/2408.05653v1", "year": 2024, "categories": ["econ.GN", "q-fin.EC"]}
{"search_keyword": "model capacity generalization", "id": "2308.02065v1", "title": "On the Biometric Capacity of Generative Face Models", "abstract": "There has been tremendous progress in generating realistic faces with high fidelity over the past few years. Despite this progress, a crucial question remains unanswered: \"Given a generative face model, how many unique identities can it generate?\" In other words, what is the biometric capacity of the generative face model? A scientific basis for answering this question will benefit evaluating and comparing different generative face models and establish an upper bound on their scalability. This paper proposes a statistical approach to estimate the biometric capacity of generated face images in a hyperspherical feature space. We employ our approach on multiple generative models, including unconditional generators like StyleGAN, Latent Diffusion Model, and \"Generated Photos,\" as well as DCFace, a class-conditional generator. We also estimate capacity w.r.t. demographic attributes such as gender and age. Our capacity estimates indicate that (a) under ArcFace representation at a false acceptance rate (FAR) of 0.1%, StyleGAN3 and DCFace have a capacity upper bound of $1.43\\times10^6$ and $1.190\\times10^4$, respectively; (b) the capacity reduces drastically as we lower the desired FAR with an estimate of $1.796\\times10^4$ and $562$ at FAR of 1% and 10%, respectively, for StyleGAN3; (c) there is no discernible disparity in the capacity w.r.t gender; and (d) for some generative models, there is an appreciable disparity in the capacity w.r.t age. Code is available at https://github.com/human-analysis/capacity-generative-face-models.", "url": "http://arxiv.org/abs/2308.02065v1", "year": 2023, "categories": ["cs.CV", "cs.AI", "cs.LG"]}
{"search_keyword": "model capacity generalization", "id": "1709.05340v1", "title": "Dynamic Capacity Estimation in Hopfield Networks", "abstract": "Understanding the memory capacity of neural networks remains a challenging problem in implementing artificial intelligence systems. In this paper, we address the notion of capacity with respect to Hopfield networks and propose a dynamic approach to monitoring a network's capacity. We define our understanding of capacity as the maximum number of stored patterns which can be retrieved when probed by the stored patterns. Prior work in this area has presented static expressions dependent on neuron count $N$, forcing network designers to assume worst-case input characteristics for bias and correlation when setting the capacity of the network. Instead, our model operates simultaneously with the learning Hopfield network and concludes on a capacity estimate based on the patterns which were stored. By continuously updating the crosstalk associated with the stored patterns, our model guards the network from overwriting its memory traces and exceeding its capacity. We simulate our model using artificially generated random patterns, which can be set to a desired bias and correlation, and observe capacity estimates between 93% and 97% accurate. As a result, our model doubles the memory efficiency of Hopfield networks in comparison to the static and worst-case capacity estimate while minimizing the risk of lost patterns.", "url": "http://arxiv.org/abs/1709.05340v1", "year": 2017, "categories": ["cs.NE", "cs.LG", "B.3.2; C.1.3; H.3.3; I.2.6"]}
{"search_keyword": "model capacity generalization", "id": "0711.2114v1", "title": "Bi-capacities -- Part I: definition, MÃ¶bius transform and interaction", "abstract": "Bi-capacities arise as a natural generalization of capacities (or fuzzy measures) in a context of decision making where underlying scales are bipolar. They are able to capture a wide variety of decision behaviours, encompassing models such as Cumulative Prospect Theory (CPT). The aim of this paper in two parts is to present the machinery behind bi-capacities, and thus remains on a rather theoretical level, although some parts are firmly rooted in decision theory, notably cooperative game theory. The present first part is devoted to the introduction of bi-capacities and the structure on which they are defined. We define the M\\\"obius transform of bi-capacities, by just applying the well known theory of M\\\" obius functions as established by Rota to the particular case of bi-capacities. Then, we introduce derivatives of bi-capacities, by analogy with what was done for pseudo-Boolean functions (another view of capacities and set functions), and this is the key point to introduce the Shapley value and the interaction index for bi-capacities. This is done in a cooperative game theoretic perspective. In summary, all familiar notions used for fuzzy measures are available in this more general framework.", "url": "http://arxiv.org/abs/0711.2114v1", "year": 2007, "categories": ["cs.DM", "cs.GT"]}
{"search_keyword": "model capacity generalization", "id": "1204.2083v1", "title": "Primary Rate-Splitting Achieves Capacity for the Gaussian Cognitive Interference Channel", "abstract": "The cognitive interference channel models cognitive overlay radio systems, where cognitive radios overhear the transmission of neighboring nodes. Capacity for this channel is not known in general. For the Gaussian case capacity is known in three regimes, usually denoted as the \"weak interference\", \"very strong interference\" and \"primary decodes cognitive\". This paper provides a new capacity result, based on rate-splitting of the primary user's message into a public and private part and that generalizes the capacity results in the \"very strong interference\" and \"primary decodes cognitive\" regimes. This result indicates that capacity of the cognitive interference channel not only depends on channel conditions but also the level of cooperation with the primary user.", "url": "http://arxiv.org/abs/1204.2083v1", "year": 2012, "categories": ["cs.IT", "math.IT"]}
{"search_keyword": "model capacity generalization", "id": "2203.09715v1", "title": "Carnot machine-based massive MIMO communication capacity modeling and performance analysis", "abstract": "Similar to the energy flowing process in traditional heat engines, information could be considered to flow in the communication systems with the form of energy and entropy. Combining the thermodynamic Carnot machine and the classical Shannon information theory, a generalized thermodynamic MIMO (multiple input multiple outputs) communication system is established to analyze the channel capacity using forward error correction codes. Based on the concepts of freedom and entropy in the communication system, the generalized channel capacity is proposed under the thermodynamic theory. Furthermore, the relationships between the proposed channel capacity and the noise freedom and coding overhead are derived and simulated. Simulation results verify the proposed channel capacity is coincident with the classical channel capacity.", "url": "http://arxiv.org/abs/2203.09715v1", "year": 2022, "categories": ["cs.IT", "math.IT"]}
{"search_keyword": "model capacity generalization", "id": "2305.13390v1", "title": "An improvement of Random Node Generator for the uniform generation of capacities", "abstract": "Capacity is an important tool in decision-making under risk and uncertainty and multi-criteria decision-making. When learning a capacity-based model, it is important to be able to generate uniformly a capacity. Due to the monotonicity constraints of a capacity, this task reveals to be very difficult. The classical Random Node Generator (RNG) algorithm is a fast-running speed capacity generator, however with poor performance. In this paper, we firstly present an exact algorithm for generating a $n$ elements' general capacity, usable when $n < 5$. Then, we present an improvement of the classical RNG by studying the distribution of the value of each element of a capacity. Furthermore, we divide it into two cases, the first one is the case without any conditions, and the second one is the case when some elements have been generated. Experimental results show that the performance of this improved algorithm is much better than the classical RNG while keeping a very reasonable computation time.", "url": "http://arxiv.org/abs/2305.13390v1", "year": 2023, "categories": ["cs.DM"]}
{"search_keyword": "model capacity generalization", "id": "2504.03706v1", "title": "A multi-scale lithium-ion battery capacity prediction using mixture of experts and patch-based MLP", "abstract": "Lithium-ion battery health management has become increasingly important as the application of batteries expands. Precise forecasting of capacity degradation is critical for ensuring the healthy usage of batteries. In this paper, we innovatively propose MSPMLP, a multi-scale capacity prediction model utilizing the mixture of experts (MoE) architecture and patch-based multi-layer perceptron (MLP) blocks, to capture both the long-term degradation trend and local capacity regeneration phenomena. Specifically, we utilize patch-based MLP blocks with varying patch sizes to extract multi-scale features from the capacity sequence. Leveraging the MoE architecture, the model adaptively integrates the extracted features, thereby enhancing its capacity and expressiveness. Finally, the future battery capacity is predicted based on the integrated features, achieving high prediction accuracy and generalization. Experimental results on the public NASA dataset indicate that MSPMLP achieves a mean absolute error (MAE) of 0.0078, improving by 41.8\\% compared to existing methods. These findings highlight that MSPMLP, owing to its multi-scale modeling capability and generalizability, provides a promising solution to the battery capacity prediction challenges caused by capacity regeneration phenomena and complex usage conditions. The code of this work is provided at https://github.com/LeiYuzhu/CapacityPredict.", "url": "http://arxiv.org/abs/2504.03706v1", "year": 2025, "categories": ["eess.SP", "cs.LG", "cs.SY", "eess.SY"]}
{"search_keyword": "model capacity generalization", "id": "2311.06426v1", "title": "Incentivizing Investment and Reliability: A Study on Electricity Capacity Markets", "abstract": "The capacity market, a marketplace to exchange available generation capacity for electricity production, provides a major revenue stream for generators and is adopted in several U.S. regions. A subject of ongoing debate, the capacity market is viewed by its proponents as a crucial mechanism to ensure system reliability, while critics highlight its drawbacks such as market distortion. Under a novel analytical framework, we rigorously evaluate the impact of the capacity market on generators' revenue and system reliability. More specifically, based on market designs at New York Independent System Operator (NYISO), we propose market equilibrium-based models to capture salient aspects of the capacity market and its interaction with the energy market. We also develop a leader-follower model to study market power. We show that the capacity market incentivizes the investment of generators with lower net cost of new entry. It also facilitates reliability by preventing significant physical withholding when the demand is relatively high. Nevertheless, the capacity market may not provide enough revenue for peaking plants. Moreover, it is susceptible to market power, which necessitates tailored market power mitigation measures depending on market dynamics. We provide further insights via large-scale experiments on data from NYISO markets.", "url": "http://arxiv.org/abs/2311.06426v1", "year": 2023, "categories": ["math.OC"]}
{"search_keyword": "few-shot learning", "id": "2306.02342v2", "title": "Deep Optimal Transport: A Practical Algorithm for Photo-realistic Image Restoration", "abstract": "We propose an image restoration algorithm that can control the perceptual quality and/or the mean square error (MSE) of any pre-trained model, trading one over the other at test time. Our algorithm is few-shot: Given about a dozen images restored by the model, it can significantly improve the perceptual quality and/or the MSE of the model for newly restored images without further training. Our approach is motivated by a recent theoretical result that links between the minimum MSE (MMSE) predictor and the predictor that minimizes the MSE under a perfect perceptual quality constraint. Specifically, it has been shown that the latter can be obtained by optimally transporting the output of the former, such that its distribution matches the source data. Thus, to improve the perceptual quality of a predictor that was originally trained to minimize MSE, we approximate the optimal transport by a linear transformation in the latent space of a variational auto-encoder, which we compute in closed-form using empirical means and covariances. Going beyond the theory, we find that applying the same procedure on models that were initially trained to achieve high perceptual quality, typically improves their perceptual quality even further. And by interpolating the results with the original output of the model, we can improve their MSE on the expense of perceptual quality. We illustrate our method on a variety of degradations applied to general content images of arbitrary dimensions.", "url": "http://arxiv.org/abs/2306.02342v2", "year": 2023, "categories": ["cs.AI"]}
{"search_keyword": "few-shot learning", "id": "1707.04849v1", "title": "Minimax deviation strategies for machine learning and recognition with short learning samples", "abstract": "The article is devoted to the problem of small learning samples in machine learning. The flaws of maximum likelihood learning and minimax learning are looked into and the concept of minimax deviation learning is introduced that is free of those flaws.", "url": "http://arxiv.org/abs/1707.04849v1", "year": 2017, "categories": ["cs.LG"]}
{"search_keyword": "few-shot learning", "id": "2001.09608v1", "title": "Some Insights into Lifelong Reinforcement Learning Systems", "abstract": "A lifelong reinforcement learning system is a learning system that has the ability to learn through trail-and-error interaction with the environment over its lifetime. In this paper, I give some arguments to show that the traditional reinforcement learning paradigm fails to model this type of learning system. Some insights into lifelong reinforcement learning are provided, along with a simplistic prototype lifelong reinforcement learning system.", "url": "http://arxiv.org/abs/2001.09608v1", "year": 2020, "categories": ["cs.LG", "stat.ML"]}
{"search_keyword": "few-shot learning", "id": "1706.05749v1", "title": "Dex: Incremental Learning for Complex Environments in Deep Reinforcement Learning", "abstract": "This paper introduces Dex, a reinforcement learning environment toolkit specialized for training and evaluation of continual learning methods as well as general reinforcement learning problems. We also present the novel continual learning method of incremental learning, where a challenging environment is solved using optimal weight initialization learned from first solving a similar easier environment. We show that incremental learning can produce vastly superior results than standard methods by providing a strong baseline method across ten Dex environments. We finally develop a saliency method for qualitative analysis of reinforcement learning, which shows the impact incremental learning has on network attention.", "url": "http://arxiv.org/abs/1706.05749v1", "year": 2017, "categories": ["stat.ML", "cs.AI", "cs.LG"]}
{"search_keyword": "few-shot learning", "id": "2004.00993v2", "title": "Augmented Q Imitation Learning (AQIL)", "abstract": "The study of unsupervised learning can be generally divided into two categories: imitation learning and reinforcement learning. In imitation learning the machine learns by mimicking the behavior of an expert system whereas in reinforcement learning the machine learns via direct environment feedback. Traditional deep reinforcement learning takes a significant time before the machine starts to converge to an optimal policy. This paper proposes Augmented Q-Imitation-Learning, a method by which deep reinforcement learning convergence can be accelerated by applying Q-imitation-learning as the initial training process in traditional Deep Q-learning.", "url": "http://arxiv.org/abs/2004.00993v2", "year": 2020, "categories": ["cs.LG", "cs.AI"]}
{"search_keyword": "few-shot learning", "id": "2505.13457v1", "title": "Tuning Learning Rates with the Cumulative-Learning Constant", "abstract": "This paper introduces a novel method for optimizing learning rates in machine learning. A previously unrecognized proportionality between learning rates and dataset sizes is discovered, providing valuable insights into how dataset scale influences training dynamics. Additionally, a cumulative learning constant is identified, offering a framework for designing and optimizing advanced learning rate schedules. These findings have the potential to enhance training efficiency and performance across a wide range of machine learning applications.", "url": "http://arxiv.org/abs/2505.13457v1", "year": 2025, "categories": ["cs.LG"]}
{"search_keyword": "few-shot learning", "id": "1606.08531v1", "title": "A Learning Algorithm for Relational Logistic Regression: Preliminary Results", "abstract": "Relational logistic regression (RLR) is a representation of conditional probability in terms of weighted formulae for modelling multi-relational data. In this paper, we develop a learning algorithm for RLR models. Learning an RLR model from data consists of two steps: 1- learning the set of formulae to be used in the model (a.k.a. structure learning) and learning the weight of each formula (a.k.a. parameter learning). For structure learning, we deploy Schmidt and Murphy's hierarchical assumption: first we learn a model with simple formulae, then more complex formulae are added iteratively only if all their sub-formulae have proven effective in previous learned models. For parameter learning, we convert the problem into a non-relational learning problem and use an off-the-shelf logistic regression learning algorithm from Weka, an open-source machine learning tool, to learn the weights. We also indicate how hidden features about the individuals can be incorporated into RLR to boost the learning performance. We compare our learning algorithm to other structure and parameter learning algorithms in the literature, and compare the performance of RLR models to standard logistic regression and RDN-Boost on a modified version of the MovieLens data-set.", "url": "http://arxiv.org/abs/1606.08531v1", "year": 2016, "categories": ["cs.AI", "cs.LG", "stat.ML"]}
{"search_keyword": "few-shot learning", "id": "1707.09835v2", "title": "Meta-SGD: Learning to Learn Quickly for Few-Shot Learning", "abstract": "Few-shot learning is challenging for learning algorithms that learn each task in isolation and from scratch. In contrast, meta-learning learns from many related tasks a meta-learner that can learn a new task more accurately and faster with fewer examples, where the choice of meta-learners is crucial. In this paper, we develop Meta-SGD, an SGD-like, easily trainable meta-learner that can initialize and adapt any differentiable learner in just one step, on both supervised learning and reinforcement learning. Compared to the popular meta-learner LSTM, Meta-SGD is conceptually simpler, easier to implement, and can be learned more efficiently. Compared to the latest meta-learner MAML, Meta-SGD has a much higher capacity by learning to learn not just the learner initialization, but also the learner update direction and learning rate, all in a single meta-learning process. Meta-SGD shows highly competitive performance for few-shot learning on regression, classification, and reinforcement learning.", "url": "http://arxiv.org/abs/1707.09835v2", "year": 2017, "categories": ["cs.LG"]}
{"search_keyword": "few-shot learning", "id": "1708.07826v1", "title": "Logistic Regression as Soft Perceptron Learning", "abstract": "We comment on the fact that gradient ascent for logistic regression has a connection with the perceptron learning algorithm. Logistic learning is the \"soft\" variant of perceptron learning.", "url": "http://arxiv.org/abs/1708.07826v1", "year": 2017, "categories": ["stat.ML", "62M45, 68Q32", "K.3.2; I.5.1"]}
{"search_keyword": "few-shot learning", "id": "2406.07983v1", "title": "Meta-Learning Neural Procedural Biases", "abstract": "The goal of few-shot learning is to generalize and achieve high performance on new unseen learning tasks, where each task has only a limited number of examples available. Gradient-based meta-learning attempts to address this challenging task by learning how to learn new tasks by embedding inductive biases informed by prior learning experiences into the components of the learning algorithm. In this work, we build upon prior research and propose Neural Procedural Bias Meta-Learning (NPBML), a novel framework designed to meta-learn task-adaptive procedural biases. Our approach aims to consolidate recent advancements in meta-learned initializations, optimizers, and loss functions by learning them simultaneously and making them adapt to each individual task to maximize the strength of the learned inductive biases. This imbues each learning task with a unique set of procedural biases which is specifically designed and selected to attain strong learning performance in only a few gradient steps. The experimental results show that by meta-learning the procedural biases of a neural network, we can induce strong inductive biases towards a distribution of learning tasks, enabling robust learning performance across many well-established few-shot learning benchmarks.", "url": "http://arxiv.org/abs/2406.07983v1", "year": 2024, "categories": ["cs.LG"]}
{"search_keyword": "statistical learning theory", "id": "1408.6618v1", "title": "Falsifiable implies Learnable", "abstract": "The paper demonstrates that falsifiability is fundamental to learning. We prove the following theorem for statistical learning and sequential prediction: If a theory is falsifiable then it is learnable -- i.e. admits a strategy that predicts optimally. An analogous result is shown for universal induction.", "url": "http://arxiv.org/abs/1408.6618v1", "year": 2014, "categories": ["cs.LG", "math.ST", "stat.ML", "stat.TH"]}
{"search_keyword": "statistical learning theory", "id": "2402.14759v1", "title": "Generalising realisability in statistical learning theory under epistemic uncertainty", "abstract": "The purpose of this paper is to look into how central notions in statistical learning theory, such as realisability, generalise under the assumption that train and test distribution are issued from the same credal set, i.e., a convex set of probability distributions. This can be considered as a first step towards a more general treatment of statistical learning under epistemic uncertainty.", "url": "http://arxiv.org/abs/2402.14759v1", "year": 2024, "categories": ["cs.LG", "cs.AI", "math.ST", "stat.TH"]}
{"search_keyword": "statistical learning theory", "id": "1908.10761v1", "title": "Lecture Notes: Selected topics on robust statistical learning theory", "abstract": "These notes gather recent results on robust statistical learning theory. The goal is to stress the main principles underlying the construction and theoretical analysis of these estimators rather than provide an exhaustive account on this rapidly growing field. The notes are the basis of lectures given at the conference StatMathAppli 2019.", "url": "http://arxiv.org/abs/1908.10761v1", "year": 2019, "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"]}
{"search_keyword": "statistical learning theory", "id": "2312.13842v2", "title": "Statistical learning theory and Occam's razor: The core argument", "abstract": "Statistical learning theory is often associated with the principle of Occam's razor, which recommends a simplicity preference in inductive inference. This paper distills the core argument for simplicity obtainable from statistical learning theory, built on the theory's central learning guarantee for the method of empirical risk minimization. This core \"means-ends\" argument is that a simpler hypothesis class or inductive model is better because it has better learning guarantees; however, these guarantees are model-relative and so the theoretical push towards simplicity is checked by our prior knowledge.", "url": "http://arxiv.org/abs/2312.13842v2", "year": 2023, "categories": ["cs.LG", "math.ST", "stat.TH"]}
{"search_keyword": "statistical learning theory", "id": "1806.09471v1", "title": "Does data interpolation contradict statistical optimality?", "abstract": "We show that learning methods interpolating the training data can achieve optimal rates for the problems of nonparametric regression and prediction with square loss.", "url": "http://arxiv.org/abs/1806.09471v1", "year": 2018, "categories": ["stat.ML", "cs.LG", "math.ST", "stat.TH"]}
{"search_keyword": "statistical learning theory", "id": "1912.10266v3", "title": "Foundations of Structural Statistics: Topological Statistical Theory", "abstract": "Topological statistical theory provides the foundation for a modern mathematical reformulation of classical statistical theory: Structural Statistics emphasizes the structural assumptions that accompany distribution families and the set of structure preserving transformations between them, given by their statistical morphisms. The resulting language is designed to integrate complicated structured model spaces like deep-learning models and to close the gap to topology and differential geometry. To preserve the compatibility to classical statistics the language comprises corresponding concepts for standard information criteria like sufficiency and completeness.", "url": "http://arxiv.org/abs/1912.10266v3", "year": 2019, "categories": ["math.ST", "cs.LG", "stat.TH", "62A01"]}
{"search_keyword": "statistical learning theory", "id": "0810.4752v1", "title": "Statistical Learning Theory: Models, Concepts, and Results", "abstract": "Statistical learning theory provides the theoretical basis for many of today's machine learning algorithms. In this article we attempt to give a gentle, non-technical overview over the key ideas and insights of statistical learning theory. We target at a broad audience, not necessarily machine learning researchers. This paper can serve as a starting point for people who want to get an overview on the field before diving into technical details.", "url": "http://arxiv.org/abs/0810.4752v1", "year": 2008, "categories": ["stat.ML", "math.ST", "stat.TH"]}
{"search_keyword": "statistical learning theory", "id": "2406.10234v3", "title": "Review and Prospect of Algebraic Research in Equivalent Framework between Statistical Mechanics and Machine Learning Theory", "abstract": "Mathematical equivalence between statistical mechanics and machine learning theory has been known since the 20th century, and research based on this equivalence has provided novel methodologies in both theoretical physics and statistical learning theory. It is well known that algebraic approaches in statistical mechanics such as operator algebra enable us to analyze phase transition phenomena mathematically. In this paper, we review and prospect algebraic research in machine learning theory for theoretical physicists who are interested in artificial intelligence. If a learning machine has a hierarchical structure or latent variables, then the random Hamiltonian cannot be expressed by any quadratic perturbation because it has singularities. To study an equilibrium state defined by such a singular random Hamiltonian, algebraic approaches are necessary to derive the asymptotic form of the free energy and the generalization error. We also introduce the most recent advance: the theoretical foundation for the alignment of artificial intelligence is now being constructed based on algebraic learning theory. This paper is devoted to the memory of Professor Huzihiro Araki who is a pioneering founder of algebraic research in both statistical mechanics and quantum field theory.", "url": "http://arxiv.org/abs/2406.10234v3", "year": 2024, "categories": ["cond-mat.stat-mech", "cs.LG", "math.ST", "stat.ML", "stat.TH"]}
{"search_keyword": "statistical learning theory", "id": "2409.18630v1", "title": "Entropy, concentration, and learning: a statistical mechanics primer", "abstract": "Artificial intelligence models trained through loss minimization have demonstrated significant success, grounded in principles from fields like information theory and statistical physics. This work explores these established connections through the lens of statistical mechanics, starting from first-principles sample concentration behaviors that underpin AI and machine learning. Our development of statistical mechanics for modeling highlights the key role of exponential families, and quantities of statistics, physics, and information theory.", "url": "http://arxiv.org/abs/2409.18630v1", "year": 2024, "categories": ["cs.LG", "cond-mat.stat-mech", "cs.AI", "cs.IT", "math.IT", "stat.ML"]}
{"search_keyword": "statistical learning theory", "id": "1802.07426v3", "title": "Generalization in Machine Learning via Analytical Learning Theory", "abstract": "This paper introduces a novel measure-theoretic theory for machine learning that does not require statistical assumptions. Based on this theory, a new regularization method in deep learning is derived and shown to outperform previous methods in CIFAR-10, CIFAR-100, and SVHN. Moreover, the proposed theory provides a theoretical basis for a family of practically successful regularization methods in deep learning. We discuss several consequences of our results on one-shot learning, representation learning, deep learning, and curriculum learning. Unlike statistical learning theory, the proposed learning theory analyzes each problem instance individually via measure theory, rather than a set of problem instances via statistics. As a result, it provides different types of results and insights when compared to statistical learning theory.", "url": "http://arxiv.org/abs/1802.07426v3", "year": 2018, "categories": ["stat.ML", "cs.AI", "cs.LG", "cs.NE"]}
{"search_keyword": "generalization bounds", "id": "cs/0411015v1", "title": "Bounded Input Bounded Predefined Control Bounded Output", "abstract": "The paper is an attempt to generalize a methodology, which is similar to the bounded-input bounded-output method currently widely used for the system stability studies. The presented earlier methodology allows decomposition of input space into bounded subspaces and defining for each subspace its bounding surface. It also defines a corresponding predefined control, which maps any point of a bounded input into a desired bounded output subspace. This methodology was improved by providing a mechanism for the fast defining a bounded surface. This paper presents enhanced bounded-input bounded-predefined-control bounded-output approach, which provides adaptability feature to the control and allows transferring of a controlled system along a suboptimal trajectory.", "url": "http://arxiv.org/abs/cs/0411015v1", "year": 2004, "categories": ["cs.AI", "I.2.8 I.2.9"]}
{"search_keyword": "generalization bounds", "id": "1306.4849v1", "title": "A generalization of bounds for cyclic codes, including the HT and BS bounds", "abstract": "We use the algebraic structure of cyclic codes and some properties of the discrete Fourier transform to give a reformulation of several classical bounds for the distance of cyclic codes, by extending techniques of linear algebra. We propose a bound, whose computational complexity is polynomial bounded, which is a generalization of the Hartmann-Tzeng bound and the Betti-Sala bound. In the majority of computed cases, our bound is the tightest among all known polynomial-time bounds, including the Roos bound.", "url": "http://arxiv.org/abs/1306.4849v1", "year": 2013, "categories": ["cs.IT", "math.CO", "math.IT"]}
{"search_keyword": "generalization bounds", "id": "1801.01329v1", "title": "Bounded normal generation is not equivalent to topological bounded normal generation", "abstract": "We show that some derived $\\mathrm{L}^1$ full groups provide examples of non simple Polish groups with the topological bounded normal generation property. In particular, it follows that there are Polish groups with the topological bounded normal generation property but not the bounded normal generation property.", "url": "http://arxiv.org/abs/1801.01329v1", "year": 2018, "categories": ["math.GR", "math.FA"]}
{"search_keyword": "generalization bounds", "id": "1305.0208v2", "title": "Perceptron Mistake Bounds", "abstract": "We present a brief survey of existing mistake bounds and introduce novel bounds for the Perceptron or the kernel Perceptron algorithm. Our novel bounds generalize beyond standard margin-loss type bounds, allow for any convex and Lipschitz loss function, and admit a very simple proof.", "url": "http://arxiv.org/abs/1305.0208v2", "year": 2013, "categories": ["cs.LG"]}
{"search_keyword": "generalization bounds", "id": "2503.06694v1", "title": "Classification of uniformly bounded simple Lie conformal algebras with upper bound one", "abstract": "In this paper, we prove that uniformly bounded simple Lie conformal algebra must be finitely generated. Furthermore, we give a completely classification of simple uniformly bounded Lie conformal algebras with upper bound one.", "url": "http://arxiv.org/abs/2503.06694v1", "year": 2025, "categories": ["math.RA"]}
{"search_keyword": "generalization bounds", "id": "2311.08156v1", "title": "Improved Spectral Bound for Quasi-Cyclic Codes", "abstract": "Spectral bounds form a powerful tool to estimate the minimum distances of quasi-cyclic codes. They generalize the defining set bounds of cyclic codes to those of quasi-cyclic codes. Based on the eigenvalues of quasi-cyclic codes and the corresponding eigenspaces, we provide an improved spectral bound for quasi-cyclic codes. Numerical results verify that the improved bound outperforms the Jensen bound in almost all cases. Based on the improved bound, we propose a general construction of quasi-cyclic codes with excellent designed minimum distances. For the quasi-cyclic codes produced by this general construction, the improved spectral bound is always sharper than the Jensen bound.", "url": "http://arxiv.org/abs/2311.08156v1", "year": 2023, "categories": ["cs.IT", "math.IT"]}
{"search_keyword": "generalization bounds", "id": "2302.14223v2", "title": "Bayesian Nagaoka-Hayashi Bound for Multiparameter Quantum-State Estimation Problem", "abstract": "In this work we propose a Bayesian version of the Nagaoka-Hayashi bound when estimating a parametric family of quantum states. This lower bound is a generalization of a recently proposed bound for point estimation to Bayesian estimation. We then show that the proposed lower bound can be efficiently computed as a semidefinite programming problem. As a lower bound, we also derive a Bayesian version of the Holevo-type bound from the Bayesian Nagaoka-Hayashi bound. Lastly, we prove that the new lower bound is tighter than the Bayesian quantum Cramer-Rao bounds.", "url": "http://arxiv.org/abs/2302.14223v2", "year": 2023, "categories": ["quant-ph"]}
{"search_keyword": "generalization bounds", "id": "2008.03360v2", "title": "Bounded Scale Measure and Property A", "abstract": "We introduce a generalization for bounded geometry that we call bounded scale measure. We show that bounded scale measure is a coarse invariant unlike bounded geometry. We then show equivalent definitions for spaces with bounded scale measure and show other properties that spaces with bounded scale measure satisfy. From there, we generalize property A from uniformly discrete metric spaces to large scale spaces with bounded geometry. Lastly, we construct a definition for property A for large scale spaces with bounded scale measure and show that this definition of property A is a coarse invariant.", "url": "http://arxiv.org/abs/2008.03360v2", "year": 2020, "categories": ["math.GT", "math.MG"]}
{"search_keyword": "generalization bounds", "id": "2309.13658v3", "title": "Fantastic Generalization Measures are Nowhere to be Found", "abstract": "We study the notion of a generalization bound being uniformly tight, meaning that the difference between the bound and the population loss is small for all learning algorithms and all population distributions. Numerous generalization bounds have been proposed in the literature as potential explanations for the ability of neural networks to generalize in the overparameterized setting. However, in their paper ``Fantastic Generalization Measures and Where to Find Them,'' Jiang et al. (2020) examine more than a dozen generalization bounds, and show empirically that none of them are uniformly tight. This raises the question of whether uniformly-tight generalization bounds are at all possible in the overparameterized setting. We consider two types of generalization bounds: (1) bounds that may depend on the training set and the learned hypothesis (e.g., margin bounds). We prove mathematically that no such bound can be uniformly tight in the overparameterized setting; (2) bounds that may in addition also depend on the learning algorithm (e.g., stability bounds). For these bounds, we show a trade-off between the algorithm's performance and the bound's tightness. Namely, if the algorithm achieves good accuracy on certain distributions, then no generalization bound can be uniformly tight for it in the overparameterized setting. We explain how these formal results can, in our view, inform research on generalization bounds for neural networks, while stressing that other interpretations of these results are also possible.", "url": "http://arxiv.org/abs/2309.13658v3", "year": 2023, "categories": ["cs.LG", "cs.NE", "stat.ML"]}
{"search_keyword": "generalization bounds", "id": "2506.04609v1", "title": "Exploring bidirectional bounds for minimax-training of Energy-based models", "abstract": "Energy-based models (EBMs) estimate unnormalized densities in an elegant framework, but they are generally difficult to train. Recent work has linked EBMs to generative adversarial networks, by noting that they can be trained through a minimax game using a variational lower bound. To avoid the instabilities caused by minimizing a lower bound, we propose to instead work with bidirectional bounds, meaning that we maximize a lower bound and minimize an upper bound when training the EBM. We investigate four different bounds on the log-likelihood derived from different perspectives. We derive lower bounds based on the singular values of the generator Jacobian and on mutual information. To upper bound the negative log-likelihood, we consider a gradient penalty-like bound, as well as one based on diffusion processes. In all cases, we provide algorithms for evaluating the bounds. We compare the different bounds to investigate, the pros and cons of the different approaches. Finally, we demonstrate that the use of bidirectional bounds stabilizes EBM training and yields high-quality density estimation and sample generation.", "url": "http://arxiv.org/abs/2506.04609v1", "year": 2025, "categories": ["cs.LG", "cs.CV"]}
