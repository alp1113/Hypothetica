Hypothetica

AI-Powered Research Originality Assessment with Multi-Agent RAG

Overview

Hypothetica is an AI-powered system that evaluates the originality of research ideas by comparing them against existing academic literature.
Instead of simple text similarity or plagiarism detection, Hypothetica performs conceptual, sentence-level novelty analysis using a multi-agent architecture, Retrieval-Augmented Generation (RAG), and evidence-grounded reasoning.

The system is designed to help researchers, students, and early-stage innovators answer a critical question before committing months of work:

‚ÄúIs my research idea actually novel?‚Äù



 What Makes Hypothetica Different?

Most existing tools:
	‚Ä¢	Detect text overlap, not idea overlap
	‚Ä¢	Provide opaque similarity scores
	‚Ä¢	Do not explain why something is considered unoriginal

Hypothetica instead:
	‚Ä¢	Evaluates conceptual originality, not plagiarism
	‚Ä¢	Produces sentence-level explanations
	‚Ä¢	Links every originality claim to retrieved academic evidence
	‚Ä¢	Uses multi-agent reasoning instead of a single LLM prompt



Core Features

Conceptual Originality Assessment
	‚Ä¢	Compares a user‚Äôs research idea against recent academic papers from arXiv
	‚Ä¢	Identifies overlaps in:
	‚Ä¢	Technical problem definition
	‚Ä¢	Methodology
	‚Ä¢	Application domain
	‚Ä¢	Innovation claims

Multi-Agent Architecture

Specialized LLM agents handle different stages:
	‚Ä¢	Keyword Agent ‚Äì generates structured search queries
	‚Ä¢	Relevance Ranking Agent ‚Äì selects the most relevant papers
	‚Ä¢	Layer-1 Analysis Agent ‚Äì evaluates each paper independently
	‚Ä¢	Layer-2 Aggregation Agent ‚Äì synthesizes global originality insights

Each agent operates with task-specific parameters for reliability and determinism.

Structured, Explainable Scoring
	‚Ä¢	Outputs a 0‚Äì100 originality score
	‚Ä¢	Uses Likert-scale categorical judgments instead of unreliable continuous scoring
	‚Ä¢	Assigns sentence-level originality labels:
	‚Ä¢	üü¢ High originality
	‚Ä¢	üü° Medium originality
	‚Ä¢	üî¥ Low originality

Each flagged sentence is linked to specific evidence from retrieved papers.

 Retrieval-Augmented Generation (RAG)
	‚Ä¢	Papers are embedded using E5 embeddings
	‚Ä¢	Stored and retrieved via ChromaDB
	‚Ä¢	Ensures all LLM reasoning is grounded in real academic content



System Architecture (High-Level)

User Research Idea
        ‚Üì
Keyword Generation Agent
        ‚Üì
arXiv Paper Retrieval
        ‚Üì
Relevance Ranking Agent
        ‚Üì
Layer-1 Per-Paper Analysis (5 papers)
        ‚Üì
Layer-2 Global Aggregation
        ‚Üì
Originality Score + Sentence-Level Report




 Technology Stack

Core
	‚Ä¢	Python 3.10
	‚Ä¢	Google Gemini 2.5 Flash
	‚Ä¢	Retrieval-Augmented Generation (RAG)

Retrieval & Embeddings
	‚Ä¢	arXiv API
	‚Ä¢	ChromaDB
	‚Ä¢	E5-base-v2 embeddings

Document Processing
	‚Ä¢	Docling (PDF ‚Üí structured Markdown)
	‚Ä¢	Custom heading extraction & section filtering

Architecture
	‚Ä¢	Modular, agent-based design
	‚Ä¢	Structured JSON outputs enforced at every stage

Frontend
	‚Ä¢	React single-page web interface
	‚Ä¢	Color-coded sentence-level feedback
	‚Ä¢	Expandable evidence views


 Evaluation Highlights
	‚Ä¢	Tested on 10 diverse research ideas
	‚Ä¢	Correctly assigns very low scores to:
	‚Ä¢	Image classification
	‚Ä¢	Sentiment analysis
	‚Ä¢	YOLO reproductions
	‚Ä¢	Rewards true novelty and novel domain combinations
	‚Ä¢	Average cost per evaluation: ~$0.013
	‚Ä¢	Stable, deterministic scoring across repeated runs



Known Limitations
	‚Ä¢	Current corpus is limited to academic literature (arXiv)
	‚Ä¢	Does not detect commercial product cloning
	‚Ä¢	e.g., a ‚ÄúFacebook-like social network‚Äù may score high
	‚Ä¢	Future versions will integrate:
	‚Ä¢	IEEE / ACM corpora
	‚Ä¢	Product & patent databases



Future Work
	‚Ä¢	Multi-corpus retrieval (ACM, IEEE, OpenAlex)
	‚Ä¢	Domain-specific originality agents
	‚Ä¢	Longitudinal novelty tracking
	‚Ä¢	Cost-optimized local model support
	‚Ä¢	Patent & commercial product awareness



Contributors
	‚Ä¢	Ahmet Alp Malko√ß ‚Äî Multi-agent pipeline, originality scoring, RAG architecture
	‚Ä¢	Harun H√ºdai Tan ‚Äî System design, evaluation framework
	‚Ä¢	Kutay Becerir ‚Äî Frontend & UX
	‚Ä¢	Baran Erol ‚Äî Research support & system testing
	‚Ä¢	Murat Karakaya ‚Äî Academic supervision



 Academic Context
	‚Ä¢	Course: SENG 491 ‚Äì Senior Project I
	‚Ä¢	Institution: TED University
	‚Ä¢	Supervisor: Dr. Murat Karakaya



 License

This project is currently intended for research and academic use.
Licensing details can be added once the project is open-sourced publicly.

